{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "DIR = 'C:\\\\Users\\\\jesse\\\\Desktop\\\\Honors Project\\\\goodreads_data\\\\raw\\\\'\n",
    "\n",
    "ya_reviews = pd.read_parquet(DIR +'ya_reviews_prepped.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_text</th>\n",
       "      <th>n_votes</th>\n",
       "      <th>n_comments</th>\n",
       "      <th>all_caps</th>\n",
       "      <th>review_text_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2767052</td>\n",
       "      <td>248c011811e945eca861b5c31a549291</td>\n",
       "      <td>5</td>\n",
       "      <td>I cracked and finally picked this up. Very enj...</td>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>i crack and finally pick this up very enjoyabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23302416</td>\n",
       "      <td>84c0936a0f9868f38e75d2f9a5cb761e</td>\n",
       "      <td>5</td>\n",
       "      <td>I read this book because my fifth grade son wa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>i read this book because my fifth grade son be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18053080</td>\n",
       "      <td>785c8db878f4009da9741dea51f641da</td>\n",
       "      <td>4</td>\n",
       "      <td>Though the book started out slow and only star...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>though the book start out slow and only start ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17383543</td>\n",
       "      <td>34dc3c45d07e82718b05e73167259aef</td>\n",
       "      <td>2</td>\n",
       "      <td>*Update - 10/27/13* - After some sleep, I thin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>after some sleep i think about allegiant overa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16651458</td>\n",
       "      <td>d8d6b590780256fef7ae4a9550fe3e0d</td>\n",
       "      <td>5</td>\n",
       "      <td>This is a moving, heartbreaking, view into a l...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>this be a move heartbreaking view into a life ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    book_id                         review_id  rating  \\\n",
       "0   2767052  248c011811e945eca861b5c31a549291       5   \n",
       "1  23302416  84c0936a0f9868f38e75d2f9a5cb761e       5   \n",
       "2  18053080  785c8db878f4009da9741dea51f641da       4   \n",
       "3  17383543  34dc3c45d07e82718b05e73167259aef       2   \n",
       "4  16651458  d8d6b590780256fef7ae4a9550fe3e0d       5   \n",
       "\n",
       "                                         review_text  n_votes  n_comments  \\\n",
       "0  I cracked and finally picked this up. Very enj...       24          25   \n",
       "1  I read this book because my fifth grade son wa...        0           0   \n",
       "2  Though the book started out slow and only star...        0           0   \n",
       "3  *Update - 10/27/13* - After some sleep, I thin...        0           0   \n",
       "4  This is a moving, heartbreaking, view into a l...        0           0   \n",
       "\n",
       "   all_caps                             review_text_lemmatized  \n",
       "0         0  i crack and finally pick this up very enjoyabl...  \n",
       "1         0  i read this book because my fifth grade son be...  \n",
       "2         0  though the book start out slow and only start ...  \n",
       "3         0  after some sleep i think about allegiant overa...  \n",
       "4         0  this be a move heartbreaking view into a life ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ya_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2388654 entries, 0 to 2388653\n",
      "Data columns (total 8 columns):\n",
      " #   Column                  Dtype \n",
      "---  ------                  ----- \n",
      " 0   book_id                 int32 \n",
      " 1   review_id               object\n",
      " 2   rating                  int8  \n",
      " 3   review_text             object\n",
      " 4   n_votes                 int16 \n",
      " 5   n_comments              int16 \n",
      " 6   all_caps                int32 \n",
      " 7   review_text_lemmatized  object\n",
      "dtypes: int16(2), int32(2), int8(1), object(3)\n",
      "memory usage: 84.3+ MB\n"
     ]
    }
   ],
   "source": [
    "ya_reviews.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ya_reviews.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.108, 'neu': 0.715, 'pos': 0.177, 'compound': 0.9766}\n",
      "{'neg': 0.033, 'neu': 0.717, 'pos': 0.25, 'compound': 0.9122}\n",
      "{'neg': 0.0, 'neu': 0.805, 'pos': 0.195, 'compound': 0.5574}\n",
      "{'neg': 0.052, 'neu': 0.905, 'pos': 0.043, 'compound': -0.7018}\n",
      "{'neg': 0.059, 'neu': 0.831, 'pos': 0.11, 'compound': 0.7795}\n",
      "{'neg': 0.052, 'neu': 0.798, 'pos': 0.149, 'compound': 0.9072}\n",
      "{'neg': 0.045, 'neu': 0.647, 'pos': 0.309, 'compound': 0.9615}\n",
      "{'neg': 0.0, 'neu': 0.173, 'pos': 0.827, 'compound': 0.6988}\n",
      "{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.8622}\n",
      "{'neg': 0.0, 'neu': 0.699, 'pos': 0.301, 'compound': 0.6948}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 0.769, 'pos': 0.231, 'compound': 0.6919}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 0.609, 'pos': 0.391, 'compound': 0.91}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.067, 'neu': 0.772, 'pos': 0.161, 'compound': 0.9073}\n",
      "{'neg': 0.021, 'neu': 0.718, 'pos': 0.26, 'compound': 0.9888}\n",
      "{'neg': 0.211, 'neu': 0.619, 'pos': 0.17, 'compound': -0.5029}\n",
      "{'neg': 0.035, 'neu': 0.739, 'pos': 0.226, 'compound': 0.8327}\n",
      "{'neg': 0.153, 'neu': 0.64, 'pos': 0.207, 'compound': 0.2732}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "{'neg': 0.159, 'neu': 0.62, 'pos': 0.221, 'compound': 0.6124}\n",
      "{'neg': 0.449, 'neu': 0.489, 'pos': 0.063, 'compound': -0.9643}\n",
      "{'neg': 0.0, 'neu': 0.43, 'pos': 0.57, 'compound': 0.6486}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\jesse\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Download the vader_lexicon\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Instantiate the sentiment intensity analyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Let's assume test['review_text_lemmatized'] is your lemmatized reviews\n",
    "test_lem_reviews = test['review_text_lemmatized']\n",
    "\n",
    "# Get the sentiment scores for each review\n",
    "sentiment_scores = [sia.polarity_scores(review) for review in test_lem_reviews]\n",
    "\n",
    "# Print the sentiment scores\n",
    "for score in sentiment_scores:\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jesse\\AppData\\Local\\Temp\\ipykernel_36944\\856955519.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['sentiment'] = sentiment_scores\n"
     ]
    }
   ],
   "source": [
    "#assign to column in dataframe\n",
    "test['sentiment'] = sentiment_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_text</th>\n",
       "      <th>n_votes</th>\n",
       "      <th>n_comments</th>\n",
       "      <th>all_caps</th>\n",
       "      <th>review_text_lemmatized</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2767052</td>\n",
       "      <td>248c011811e945eca861b5c31a549291</td>\n",
       "      <td>5</td>\n",
       "      <td>I cracked and finally picked this up. Very enj...</td>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>i crack and finally pick this up very enjoyabl...</td>\n",
       "      <td>{'neg': 0.108, 'neu': 0.715, 'pos': 0.177, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23302416</td>\n",
       "      <td>84c0936a0f9868f38e75d2f9a5cb761e</td>\n",
       "      <td>5</td>\n",
       "      <td>I read this book because my fifth grade son wa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>i read this book because my fifth grade son be...</td>\n",
       "      <td>{'neg': 0.033, 'neu': 0.717, 'pos': 0.25, 'com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18053080</td>\n",
       "      <td>785c8db878f4009da9741dea51f641da</td>\n",
       "      <td>4</td>\n",
       "      <td>Though the book started out slow and only star...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>though the book start out slow and only start ...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.805, 'pos': 0.195, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17383543</td>\n",
       "      <td>34dc3c45d07e82718b05e73167259aef</td>\n",
       "      <td>2</td>\n",
       "      <td>*Update - 10/27/13* - After some sleep, I thin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>after some sleep i think about allegiant overa...</td>\n",
       "      <td>{'neg': 0.052, 'neu': 0.905, 'pos': 0.043, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16651458</td>\n",
       "      <td>d8d6b590780256fef7ae4a9550fe3e0d</td>\n",
       "      <td>5</td>\n",
       "      <td>This is a moving, heartbreaking, view into a l...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>this be a move heartbreaking view into a life ...</td>\n",
       "      <td>{'neg': 0.059, 'neu': 0.831, 'pos': 0.11, 'com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10782699</td>\n",
       "      <td>972ce1267de0213e3032c685386890e6</td>\n",
       "      <td>5</td>\n",
       "      <td>I never thought I would enjoy a zombie books w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>i never think i would enjoy a zombie book with...</td>\n",
       "      <td>{'neg': 0.052, 'neu': 0.798, 'pos': 0.149, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7260188</td>\n",
       "      <td>21063e8930ec28bc54e76f932aa30ce1</td>\n",
       "      <td>5</td>\n",
       "      <td>What a great ending to the trilogy!! The secon...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>what a great end to the trilogy ! ! the second...</td>\n",
       "      <td>{'neg': 0.045, 'neu': 0.647, 'pos': 0.309, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6148028</td>\n",
       "      <td>a19c6c44a40a88c8ff825f40118a9c7c</td>\n",
       "      <td>5</td>\n",
       "      <td>LOVED IT!!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>love it ! !</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.173, 'pos': 0.827, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2767052</td>\n",
       "      <td>c52e231744768e9d7f939d1cbeb87666</td>\n",
       "      <td>5</td>\n",
       "      <td>Exciting, fun, entertaining! :)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>excite fun entertaining !</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13206828</td>\n",
       "      <td>1d5b64fe0408bb5e1824d14631ccb5ee</td>\n",
       "      <td>5</td>\n",
       "      <td>LET'S JUST SAY I AM SO THANKFUL I HAVE THE NEX...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>let u just say i be so thankful i have the nex...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.699, 'pos': 0.301, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>13206900</td>\n",
       "      <td>9de8dc1b8fa869233251e2a6eb783552</td>\n",
       "      <td>4</td>\n",
       "      <td>I can't believe it's over dY~C/</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>i can not believe it be over dy~c/</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13206760</td>\n",
       "      <td>1fc0c08b3224b734b51996989ce52344</td>\n",
       "      <td>5</td>\n",
       "      <td>I didn't know if I would enjoy the book being ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>i do not know if i would enjoy the book be so ...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.769, 'pos': 0.231, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>18658071</td>\n",
       "      <td>6ab2888fabae6d54a9483156a35bd319</td>\n",
       "      <td>2</td>\n",
       "      <td>It just... Didn't really make any logical sense</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>it just do not really make any logical sense</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>29275562</td>\n",
       "      <td>69539632d9918511b948fa18c87d48a4</td>\n",
       "      <td>5</td>\n",
       "      <td>I liked it much more than the first one to be ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>i like it much more than the first one to be h...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.609, 'pos': 0.391, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2802316</td>\n",
       "      <td>c4c2068c9e87c2f9f51cabb5c09163ee</td>\n",
       "      <td>4</td>\n",
       "      <td>I literally cannot deal with my heart right now</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>i literally can not deal with my heart right now</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9593913</td>\n",
       "      <td>61f67f77d2605022de5cf746e13d31c2</td>\n",
       "      <td>3</td>\n",
       "      <td>The ending felt really abrupt. I feel like the...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>the end felt really abrupt i feel like there b...</td>\n",
       "      <td>{'neg': 0.067, 'neu': 0.772, 'pos': 0.161, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>26074181</td>\n",
       "      <td>c79dd0093c7d13b6843d1c8050eb7231</td>\n",
       "      <td>3</td>\n",
       "      <td>*Minor spoilers* \\n Okay... Listen... I love t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>okay listen i love this series a lot but this ...</td>\n",
       "      <td>{'neg': 0.021, 'neu': 0.718, 'pos': 0.26, 'com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20572939</td>\n",
       "      <td>812febaa143162ed49152547ff7a3e08</td>\n",
       "      <td>5</td>\n",
       "      <td>There was sobbing. Quite a lot. \\n The last fe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>there be sob quite a lot the last few chapter ...</td>\n",
       "      <td>{'neg': 0.211, 'neu': 0.619, 'pos': 0.17, 'com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7631105</td>\n",
       "      <td>1c275d11804f2e731094337249d1bb50</td>\n",
       "      <td>4</td>\n",
       "      <td>I have to admit... This book was amazing for a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>i have to admit this book be amaze for a seque...</td>\n",
       "      <td>{'neg': 0.035, 'neu': 0.739, 'pos': 0.226, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>13188676</td>\n",
       "      <td>540daa321648be66f867791b5a1aa85f</td>\n",
       "      <td>5</td>\n",
       "      <td>I CANT EVEN EXPRESS MY EMOTIONS OH GEEZ I LOVE...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>i can not even express my emotion oh geez i lo...</td>\n",
       "      <td>{'neg': 0.153, 'neu': 0.64, 'pos': 0.207, 'com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>13623150</td>\n",
       "      <td>70ebc0d4940def9bbaa54c029bb2b8a0</td>\n",
       "      <td>5</td>\n",
       "      <td>Oh Warner...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>oh warner</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>13104080</td>\n",
       "      <td>528000001d6705f260ac8c7a58327018</td>\n",
       "      <td>5</td>\n",
       "      <td>Warner. I need more Warner this second. That's...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>warner i need more warner this second that be all</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>13508069</td>\n",
       "      <td>5b12c5a78b6c7d41c601555bbf8a088f</td>\n",
       "      <td>5</td>\n",
       "      <td>I just... I can't. I completely can't. \\n Thos...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>i just i can not i completely can not those la...</td>\n",
       "      <td>{'neg': 0.159, 'neu': 0.62, 'pos': 0.221, 'com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>8803932</td>\n",
       "      <td>21c41d209d0e13c55a73c5208f11f952</td>\n",
       "      <td>5</td>\n",
       "      <td>When I read that ending I was crying, then sha...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>when i read that end i be cry then shake then ...</td>\n",
       "      <td>{'neg': 0.449, 'neu': 0.489, 'pos': 0.063, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>11454587</td>\n",
       "      <td>b3881c3c1c9e0993e5d4f14971d914ac</td>\n",
       "      <td>5</td>\n",
       "      <td>Sigh. Archer. I love you so much.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sigh archer i love you so much</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.43, 'pos': 0.57, 'compou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     book_id                         review_id  rating  \\\n",
       "0    2767052  248c011811e945eca861b5c31a549291       5   \n",
       "1   23302416  84c0936a0f9868f38e75d2f9a5cb761e       5   \n",
       "2   18053080  785c8db878f4009da9741dea51f641da       4   \n",
       "3   17383543  34dc3c45d07e82718b05e73167259aef       2   \n",
       "4   16651458  d8d6b590780256fef7ae4a9550fe3e0d       5   \n",
       "5   10782699  972ce1267de0213e3032c685386890e6       5   \n",
       "6    7260188  21063e8930ec28bc54e76f932aa30ce1       5   \n",
       "7    6148028  a19c6c44a40a88c8ff825f40118a9c7c       5   \n",
       "8    2767052  c52e231744768e9d7f939d1cbeb87666       5   \n",
       "9   13206828  1d5b64fe0408bb5e1824d14631ccb5ee       5   \n",
       "10  13206900  9de8dc1b8fa869233251e2a6eb783552       4   \n",
       "11  13206760  1fc0c08b3224b734b51996989ce52344       5   \n",
       "12  18658071  6ab2888fabae6d54a9483156a35bd319       2   \n",
       "13  29275562  69539632d9918511b948fa18c87d48a4       5   \n",
       "14   2802316  c4c2068c9e87c2f9f51cabb5c09163ee       4   \n",
       "15   9593913  61f67f77d2605022de5cf746e13d31c2       3   \n",
       "16  26074181  c79dd0093c7d13b6843d1c8050eb7231       3   \n",
       "17  20572939  812febaa143162ed49152547ff7a3e08       5   \n",
       "18   7631105  1c275d11804f2e731094337249d1bb50       4   \n",
       "19  13188676  540daa321648be66f867791b5a1aa85f       5   \n",
       "20  13623150  70ebc0d4940def9bbaa54c029bb2b8a0       5   \n",
       "21  13104080  528000001d6705f260ac8c7a58327018       5   \n",
       "22  13508069  5b12c5a78b6c7d41c601555bbf8a088f       5   \n",
       "23   8803932  21c41d209d0e13c55a73c5208f11f952       5   \n",
       "24  11454587  b3881c3c1c9e0993e5d4f14971d914ac       5   \n",
       "\n",
       "                                          review_text  n_votes  n_comments  \\\n",
       "0   I cracked and finally picked this up. Very enj...       24          25   \n",
       "1   I read this book because my fifth grade son wa...        0           0   \n",
       "2   Though the book started out slow and only star...        0           0   \n",
       "3   *Update - 10/27/13* - After some sleep, I thin...        0           0   \n",
       "4   This is a moving, heartbreaking, view into a l...        0           0   \n",
       "5   I never thought I would enjoy a zombie books w...        0           0   \n",
       "6   What a great ending to the trilogy!! The secon...        0           0   \n",
       "7                                          LOVED IT!!        0           0   \n",
       "8                     Exciting, fun, entertaining! :)        0           0   \n",
       "9   LET'S JUST SAY I AM SO THANKFUL I HAVE THE NEX...        0           0   \n",
       "10                    I can't believe it's over dY~C/        0           0   \n",
       "11  I didn't know if I would enjoy the book being ...        0           0   \n",
       "12    It just... Didn't really make any logical sense        0           0   \n",
       "13  I liked it much more than the first one to be ...        0           0   \n",
       "14    I literally cannot deal with my heart right now        0           0   \n",
       "15  The ending felt really abrupt. I feel like the...        0           3   \n",
       "16  *Minor spoilers* \\n Okay... Listen... I love t...        0           0   \n",
       "17  There was sobbing. Quite a lot. \\n The last fe...        0           0   \n",
       "18  I have to admit... This book was amazing for a...        0           0   \n",
       "19  I CANT EVEN EXPRESS MY EMOTIONS OH GEEZ I LOVE...        0           0   \n",
       "20                                       Oh Warner...        0           0   \n",
       "21  Warner. I need more Warner this second. That's...        0           0   \n",
       "22  I just... I can't. I completely can't. \\n Thos...        1           0   \n",
       "23  When I read that ending I was crying, then sha...        1           0   \n",
       "24                  Sigh. Archer. I love you so much.        0           0   \n",
       "\n",
       "    all_caps                             review_text_lemmatized  \\\n",
       "0          0  i crack and finally pick this up very enjoyabl...   \n",
       "1          0  i read this book because my fifth grade son be...   \n",
       "2          0  though the book start out slow and only start ...   \n",
       "3          0  after some sleep i think about allegiant overa...   \n",
       "4          0  this be a move heartbreaking view into a life ...   \n",
       "5          0  i never think i would enjoy a zombie book with...   \n",
       "6          0  what a great end to the trilogy ! ! the second...   \n",
       "7          1                                        love it ! !   \n",
       "8          0                          excite fun entertaining !   \n",
       "9          1  let u just say i be so thankful i have the nex...   \n",
       "10         0                 i can not believe it be over dy~c/   \n",
       "11         1  i do not know if i would enjoy the book be so ...   \n",
       "12         0       it just do not really make any logical sense   \n",
       "13         0  i like it much more than the first one to be h...   \n",
       "14         0   i literally can not deal with my heart right now   \n",
       "15         1  the end felt really abrupt i feel like there b...   \n",
       "16         1  okay listen i love this series a lot but this ...   \n",
       "17         0  there be sob quite a lot the last few chapter ...   \n",
       "18         0  i have to admit this book be amaze for a seque...   \n",
       "19         1  i can not even express my emotion oh geez i lo...   \n",
       "20         0                                          oh warner   \n",
       "21         0  warner i need more warner this second that be all   \n",
       "22         1  i just i can not i completely can not those la...   \n",
       "23         0  when i read that end i be cry then shake then ...   \n",
       "24         0                     sigh archer i love you so much   \n",
       "\n",
       "                                            sentiment  \n",
       "0   {'neg': 0.108, 'neu': 0.715, 'pos': 0.177, 'co...  \n",
       "1   {'neg': 0.033, 'neu': 0.717, 'pos': 0.25, 'com...  \n",
       "2   {'neg': 0.0, 'neu': 0.805, 'pos': 0.195, 'comp...  \n",
       "3   {'neg': 0.052, 'neu': 0.905, 'pos': 0.043, 'co...  \n",
       "4   {'neg': 0.059, 'neu': 0.831, 'pos': 0.11, 'com...  \n",
       "5   {'neg': 0.052, 'neu': 0.798, 'pos': 0.149, 'co...  \n",
       "6   {'neg': 0.045, 'neu': 0.647, 'pos': 0.309, 'co...  \n",
       "7   {'neg': 0.0, 'neu': 0.173, 'pos': 0.827, 'comp...  \n",
       "8   {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...  \n",
       "9   {'neg': 0.0, 'neu': 0.699, 'pos': 0.301, 'comp...  \n",
       "10  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "11  {'neg': 0.0, 'neu': 0.769, 'pos': 0.231, 'comp...  \n",
       "12  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "13  {'neg': 0.0, 'neu': 0.609, 'pos': 0.391, 'comp...  \n",
       "14  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "15  {'neg': 0.067, 'neu': 0.772, 'pos': 0.161, 'co...  \n",
       "16  {'neg': 0.021, 'neu': 0.718, 'pos': 0.26, 'com...  \n",
       "17  {'neg': 0.211, 'neu': 0.619, 'pos': 0.17, 'com...  \n",
       "18  {'neg': 0.035, 'neu': 0.739, 'pos': 0.226, 'co...  \n",
       "19  {'neg': 0.153, 'neu': 0.64, 'pos': 0.207, 'com...  \n",
       "20  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "21  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "22  {'neg': 0.159, 'neu': 0.62, 'pos': 0.221, 'com...  \n",
       "23  {'neg': 0.449, 'neu': 0.489, 'pos': 0.063, 'co...  \n",
       "24  {'neg': 0.0, 'neu': 0.43, 'pos': 0.57, 'compou...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Instantiate the vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit the vectorizer to the data\n",
    "vectorizer.fit(test['review_text_lemmatized'])\n",
    "\n",
    "# Transform the texts into TF-IDF vectors\n",
    "tfidf_vectors = vectorizer.transform(test['review_text_lemmatized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "# Define your model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=10000, output_dim=256))  # input_dim should be the size of your vocabulary\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(10000, activation='softmax'))  # output_dim should be the size of your vocabulary\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "# Train the model\n",
    "# x_train and y_train should be your preprocessed text data\n",
    "# Each sample in x_train is a sequence of word indices, and the corresponding sample in y_train is the next word\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Let's assume you have a list of lemmatized texts, each text is a list of words\n",
    "lemmatized_texts = [['word1', 'word2', 'word3'], ['word4', 'word5', 'word6'], ...]\n",
    "\n",
    "# Train a Word2Vec model\n",
    "model = Word2Vec(lemmatized_texts, size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Get the word vector for a given word\n",
    "word_vector = model.wv['word1']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
